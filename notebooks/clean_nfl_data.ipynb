{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup  \n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and clean the data to return df's with only PUP, D, O  or IR designations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bengals2015 = pd.read_csv('../clean_data/bengals2015.csv')\n",
    "bengals2016 = pd.read_csv('../clean_data/bengals2016.csv')\n",
    "bengals2017 = pd.read_csv('../clean_data/bengals2017.csv')\n",
    "bengals2018 = pd.read_csv('../clean_data/bengals2018.csv')\n",
    "bengals2019 = pd.read_csv('../clean_data/bengals2019.csv')\n",
    "bengals2020 = pd.read_csv('../clean_data/bengals2020.csv')\n",
    "\n",
    "bengals2015 = bengals2015[bengals2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "bengals2015 = bengals2015.reset_index(drop = True)\n",
    "\n",
    "bengals2016 = bengals2016[bengals2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "bengals2016 = bengals2016.reset_index(drop = True)\n",
    "\n",
    "bengals2017 = bengals2017[bengals2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "bengals2017 = bengals2017.reset_index(drop = True)\n",
    "\n",
    "bengals2018 = bengals2018[bengals2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "bengals2018 = bengals2018.reset_index(drop = True)\n",
    "\n",
    "bengals2019 = bengals2019[bengals2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "bengals2019 = bengals2019.reset_index(drop = True)\n",
    "\n",
    "bengals2020 = bengals2020[bengals2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "bengals2020 = bengals2020.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import to csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bengals2015.to_csv('../cleanest_data/bengals2015.csv', index = False)\n",
    "bengals2016.to_csv('../cleanest_data/bengals2016.csv', index = False)\n",
    "bengals2017.to_csv('../cleanest_data/bengals2017.csv', index = False)\n",
    "bengals2018.to_csv('../cleanest_data/bengals2018.csv', index = False)\n",
    "bengals2019.to_csv('../cleanest_data/bengals2019.csv', index = False)\n",
    "bengals2020.to_csv('../cleanest_data/bengals2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now do the remaining 31 NFL Teams the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bills2015 = pd.read_csv('../clean_data/bills2015.csv')\n",
    "bills2016 = pd.read_csv('../clean_data/bills2016.csv')\n",
    "bills2017 = pd.read_csv('../clean_data/bills2017.csv')\n",
    "bills2018 = pd.read_csv('../clean_data/bills2018.csv')\n",
    "bills2019 = pd.read_csv('../clean_data/bills2019.csv')\n",
    "bills2020 = pd.read_csv('../clean_data/bills2020.csv')\n",
    "\n",
    "bills2015 = bills2015[bills2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "bills2015 = bills2015.reset_index(drop = True)\n",
    "\n",
    "bills2016 = bills2016[bills2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "bills2016 = bills2016.reset_index(drop = True)\n",
    "\n",
    "bills2017 = bills2017[bills2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "bills2017 = bills2017.reset_index(drop = True)\n",
    "\n",
    "bills2018 = bills2018[bills2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "bills2018 = bills2018.reset_index(drop = True)\n",
    "\n",
    "bills2019 = bills2019[bills2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "bills2019 = bills2019.reset_index(drop = True)\n",
    "\n",
    "bills2020 = bills2020[bills2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "bills2020 = bills2020.reset_index(drop = True)\n",
    "\n",
    "bills2015.to_csv('../cleanest_data/bills2015.csv', index = False)\n",
    "bills2016.to_csv('../cleanest_data/bills2016.csv', index = False)\n",
    "bills2017.to_csv('../cleanest_data/bills2017.csv', index = False)\n",
    "bills2018.to_csv('../cleanest_data/bills2018.csv', index = False)\n",
    "bills2019.to_csv('../cleanest_data/bills2019.csv', index = False)\n",
    "bills2020.to_csv('../cleanest_data/bills2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "broncos2015 = pd.read_csv('../clean_data/broncos2015.csv')\n",
    "broncos2016 = pd.read_csv('../clean_data/broncos2016.csv')\n",
    "broncos2017 = pd.read_csv('../clean_data/broncos2017.csv')\n",
    "broncos2018 = pd.read_csv('../clean_data/broncos2018.csv')\n",
    "broncos2019 = pd.read_csv('../clean_data/broncos2019.csv')\n",
    "broncos2020 = pd.read_csv('../clean_data/broncos2020.csv')\n",
    "\n",
    "broncos2015 = broncos2015[broncos2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "broncos2015 = broncos2015.reset_index(drop = True)\n",
    "\n",
    "broncos2016 = broncos2016[broncos2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "broncos2016 = broncos2016.reset_index(drop = True)\n",
    "\n",
    "broncos2017 = broncos2017[broncos2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "broncos2017 = broncos2017.reset_index(drop = True)\n",
    "\n",
    "broncos2018 = broncos2018[broncos2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "broncos2018 = broncos2018.reset_index(drop = True)\n",
    "\n",
    "broncos2019 = broncos2019[broncos2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "broncos2019 = broncos2019.reset_index(drop = True)\n",
    "\n",
    "broncos2020 = broncos2020[broncos2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "broncos2020 = broncos2020.reset_index(drop = True)\n",
    "\n",
    "broncos2015.to_csv('../cleanest_data/broncos2015.csv', index = False)\n",
    "broncos2016.to_csv('../cleanest_data/broncos2016.csv', index = False)\n",
    "broncos2017.to_csv('../cleanest_data/broncos2017.csv', index = False)\n",
    "broncos2018.to_csv('../cleanest_data/broncos2018.csv', index = False)\n",
    "broncos2019.to_csv('../cleanest_data/broncos2019.csv', index = False)\n",
    "broncos2020.to_csv('../cleanest_data/broncos2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "browns2015 = pd.read_csv('../clean_data/browns2015.csv')\n",
    "browns2016 = pd.read_csv('../clean_data/browns2016.csv')\n",
    "browns2017 = pd.read_csv('../clean_data/browns2017.csv')\n",
    "browns2018 = pd.read_csv('../clean_data/browns2018.csv')\n",
    "browns2019 = pd.read_csv('../clean_data/browns2019.csv')\n",
    "browns2020 = pd.read_csv('../clean_data/browns2020.csv')\n",
    "\n",
    "browns2015 = browns2015[browns2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "browns2015 = browns2015.reset_index(drop = True)\n",
    "\n",
    "browns2016 = browns2016[browns2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "browns2016 = browns2016.reset_index(drop = True)\n",
    "\n",
    "browns2017 = browns2017[browns2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "browns2017 = browns2017.reset_index(drop = True)\n",
    "\n",
    "browns2018 = browns2018[browns2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "browns2018 = browns2018.reset_index(drop = True)\n",
    "\n",
    "browns2019 = browns2019[browns2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "browns2019 = browns2019.reset_index(drop = True)\n",
    "\n",
    "browns2020 = browns2020[browns2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "browns2020 = browns2020.reset_index(drop = True)\n",
    "\n",
    "browns2015.to_csv('../cleanest_data/browns2015.csv', index = False)\n",
    "browns2016.to_csv('../cleanest_data/browns2016.csv', index = False)\n",
    "browns2017.to_csv('../cleanest_data/browns2017.csv', index = False)\n",
    "browns2018.to_csv('../cleanest_data/browns2018.csv', index = False)\n",
    "browns2019.to_csv('../cleanest_data/browns2019.csv', index = False)\n",
    "browns2020.to_csv('../cleanest_data/browns2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "buccaneers2015 = pd.read_csv('../clean_data/buccaneers2015.csv')\n",
    "buccaneers2016 = pd.read_csv('../clean_data/buccaneers2016.csv')\n",
    "buccaneers2017 = pd.read_csv('../clean_data/buccaneers2017.csv')\n",
    "buccaneers2018 = pd.read_csv('../clean_data/buccaneers2018.csv')\n",
    "buccaneers2019 = pd.read_csv('../clean_data/buccaneers2019.csv')\n",
    "buccaneers2020 = pd.read_csv('../clean_data/buccaneers2020.csv')\n",
    "\n",
    "buccaneers2015 = buccaneers2015[buccaneers2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "buccaneers2015 = buccaneers2015.reset_index(drop = True)\n",
    "\n",
    "buccaneers2016 = buccaneers2016[buccaneers2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "buccaneers2016 = buccaneers2016.reset_index(drop = True)\n",
    "\n",
    "buccaneers2017 = buccaneers2017[buccaneers2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "buccaneers2017 = buccaneers2017.reset_index(drop = True)\n",
    "\n",
    "buccaneers2018 = buccaneers2018[buccaneers2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "buccaneers2018 = buccaneers2018.reset_index(drop = True)\n",
    "\n",
    "buccaneers2019 = buccaneers2019[buccaneers2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "buccaneers2019 = buccaneers2019.reset_index(drop = True)\n",
    "\n",
    "buccaneers2020 = buccaneers2020[buccaneers2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "buccaneers2020 = buccaneers2020.reset_index(drop = True)\n",
    "\n",
    "buccaneers2015.to_csv('../cleanest_data/buccaneers2015.csv', index = False)\n",
    "buccaneers2016.to_csv('../cleanest_data/buccaneers2016.csv', index = False)\n",
    "buccaneers2017.to_csv('../cleanest_data/buccaneers2017.csv', index = False)\n",
    "buccaneers2018.to_csv('../cleanest_data/buccaneers2018.csv', index = False)\n",
    "buccaneers2019.to_csv('../cleanest_data/buccaneers2019.csv', index = False)\n",
    "buccaneers2020.to_csv('../cleanest_data/buccaneers2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardinals2015 = pd.read_csv('../clean_data/cardinals2015.csv')\n",
    "cardinals2016 = pd.read_csv('../clean_data/cardinals2016.csv')\n",
    "cardinals2017 = pd.read_csv('../clean_data/cardinals2017.csv')\n",
    "cardinals2018 = pd.read_csv('../clean_data/cardinals2018.csv')\n",
    "cardinals2019 = pd.read_csv('../clean_data/cardinals2019.csv')\n",
    "cardinals2020 = pd.read_csv('../clean_data/cardinals2020.csv')\n",
    "\n",
    "cardinals2015 = cardinals2015[cardinals2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "cardinals2015 = cardinals2015.reset_index(drop = True)\n",
    "\n",
    "cardinals2016 = cardinals2016[cardinals2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "cardinals2016 = cardinals2016.reset_index(drop = True)\n",
    "\n",
    "cardinals2017 = cardinals2017[cardinals2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "cardinals2017 = cardinals2017.reset_index(drop = True)\n",
    "\n",
    "cardinals2018 = cardinals2018[cardinals2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "cardinals2018 = cardinals2018.reset_index(drop = True)\n",
    "\n",
    "cardinals2019 = cardinals2019[cardinals2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "cardinals2019 = cardinals2019.reset_index(drop = True)\n",
    "\n",
    "cardinals2020 = cardinals2020[cardinals2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "cardinals2020 = cardinals2020.reset_index(drop = True)\n",
    "\n",
    "cardinals2015.to_csv('../cleanest_data/cardinals2015.csv', index = False)\n",
    "cardinals2016.to_csv('../cleanest_data/cardinals2016.csv', index = False)\n",
    "cardinals2017.to_csv('../cleanest_data/cardinals2017.csv', index = False)\n",
    "cardinals2018.to_csv('../cleanest_data/cardinals2018.csv', index = False)\n",
    "cardinals2019.to_csv('../cleanest_data/cardinals2019.csv', index = False)\n",
    "cardinals2020.to_csv('../cleanest_data/cardinals2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chargers2015 = pd.read_csv('../clean_data/chargers2015.csv')\n",
    "chargers2016 = pd.read_csv('../clean_data/chargers2016.csv')\n",
    "chargers2017 = pd.read_csv('../clean_data/chargers2017.csv')\n",
    "chargers2018 = pd.read_csv('../clean_data/chargers2018.csv')\n",
    "chargers2019 = pd.read_csv('../clean_data/chargers2019.csv')\n",
    "chargers2020 = pd.read_csv('../clean_data/chargers2020.csv')\n",
    "\n",
    "chargers2015 = chargers2015[chargers2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "chargers2015 = chargers2015.reset_index(drop = True)\n",
    "\n",
    "chargers2016 = chargers2016[chargers2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "chargers2016 = chargers2016.reset_index(drop = True)\n",
    "\n",
    "chargers2017 = chargers2017[chargers2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "chargers2017 = chargers2017.reset_index(drop = True)\n",
    "\n",
    "chargers2018 = chargers2018[chargers2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "chargers2018 = chargers2018.reset_index(drop = True)\n",
    "\n",
    "chargers2019 = chargers2019[chargers2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "chargers2019 = chargers2019.reset_index(drop = True)\n",
    "\n",
    "chargers2020 = chargers2020[chargers2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "chargers2020 = chargers2020.reset_index(drop = True)\n",
    "\n",
    "chargers2015.to_csv('../cleanest_data/chargers2015.csv', index = False)\n",
    "chargers2016.to_csv('../cleanest_data/chargers2016.csv', index = False)\n",
    "chargers2017.to_csv('../cleanest_data/chargers2017.csv', index = False)\n",
    "chargers2018.to_csv('../cleanest_data/chargers2018.csv', index = False)\n",
    "chargers2019.to_csv('../cleanest_data/chargers2019.csv', index = False)\n",
    "chargers2020.to_csv('../cleanest_data/chargers2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago2015 = pd.read_csv('../clean_data/chicago2015.csv')\n",
    "chicago2016 = pd.read_csv('../clean_data/chicago2016.csv')\n",
    "chicago2017 = pd.read_csv('../clean_data/chicago2017.csv')\n",
    "chicago2018 = pd.read_csv('../clean_data/chicago2018.csv')\n",
    "chicago2019 = pd.read_csv('../clean_data/chicago2019.csv')\n",
    "chicago2020 = pd.read_csv('../clean_data/chicago2020.csv')\n",
    "\n",
    "chicago2015 = chicago2015[chicago2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "chicago2015 = chicago2015.reset_index(drop = True)\n",
    "\n",
    "chicago2016 = chicago2016[chicago2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "chicago2016 = chicago2016.reset_index(drop = True)\n",
    "\n",
    "chicago2017 = chicago2017[chicago2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "chicago2017 = chicago2017.reset_index(drop = True)\n",
    "\n",
    "chicago2018 = chicago2018[chicago2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "chicago2018 = chicago2018.reset_index(drop = True)\n",
    "\n",
    "chicago2019 = chicago2019[chicago2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "chicago2019 = chicago2019.reset_index(drop = True)\n",
    "\n",
    "chicago2020 = chicago2020[chicago2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "chicago2020 = chicago2020.reset_index(drop = True)\n",
    "\n",
    "chicago2015.to_csv('../cleanest_data/chicago2015.csv', index = False)\n",
    "chicago2016.to_csv('../cleanest_data/chicago2016.csv', index = False)\n",
    "chicago2017.to_csv('../cleanest_data/chicago2017.csv', index = False)\n",
    "chicago2018.to_csv('../cleanest_data/chicago2018.csv', index = False)\n",
    "chicago2019.to_csv('../cleanest_data/chicago2019.csv', index = False)\n",
    "chicago2020.to_csv('../cleanest_data/chicago2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiefs2015 = pd.read_csv('../clean_data/chiefs2015.csv')\n",
    "chiefs2016 = pd.read_csv('../clean_data/chiefs2016.csv')\n",
    "chiefs2017 = pd.read_csv('../clean_data/chiefs2017.csv')\n",
    "chiefs2018 = pd.read_csv('../clean_data/chiefs2018.csv')\n",
    "chiefs2019 = pd.read_csv('../clean_data/chiefs2019.csv')\n",
    "chiefs2020 = pd.read_csv('../clean_data/chiefs2020.csv')\n",
    "\n",
    "chiefs2015 = chiefs2015[chiefs2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "chiefs2015 = chiefs2015.reset_index(drop = True)\n",
    "\n",
    "chiefs2016 = chiefs2016[chiefs2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "chiefs2016 = chiefs2016.reset_index(drop = True)\n",
    "\n",
    "chiefs2017 = chiefs2017[chiefs2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "chiefs2017 = chiefs2017.reset_index(drop = True)\n",
    "\n",
    "chiefs2018 = chiefs2018[chiefs2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "chiefs2018 = chiefs2018.reset_index(drop = True)\n",
    "\n",
    "chiefs2019 = chiefs2019[chiefs2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "chiefs2019 = chiefs2019.reset_index(drop = True)\n",
    "\n",
    "chiefs2020 = chiefs2020[chiefs2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "chiefs2020 = chiefs2020.reset_index(drop = True)\n",
    "\n",
    "chiefs2015.to_csv('../cleanest_data/chiefs2015.csv', index = False)\n",
    "chiefs2016.to_csv('../cleanest_data/chiefs2016.csv', index = False)\n",
    "chiefs2017.to_csv('../cleanest_data/chiefs2017.csv', index = False)\n",
    "chiefs2018.to_csv('../cleanest_data/chiefs2018.csv', index = False)\n",
    "chiefs2019.to_csv('../cleanest_data/chiefs2019.csv', index = False)\n",
    "chiefs2020.to_csv('../cleanest_data/chiefs2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "colts2015 = pd.read_csv('../clean_data/colts2015.csv')\n",
    "colts2016 = pd.read_csv('../clean_data/colts2016.csv')\n",
    "colts2017 = pd.read_csv('../clean_data/colts2017.csv')\n",
    "colts2018 = pd.read_csv('../clean_data/colts2018.csv')\n",
    "colts2019 = pd.read_csv('../clean_data/colts2019.csv')\n",
    "colts2020 = pd.read_csv('../clean_data/colts2020.csv')\n",
    "\n",
    "colts2015 = colts2015[colts2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "colts2015 = colts2015.reset_index(drop = True)\n",
    "\n",
    "colts2016 = colts2016[colts2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "colts2016 = colts2016.reset_index(drop = True)\n",
    "\n",
    "colts2017 = colts2017[colts2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "colts2017 = colts2017.reset_index(drop = True)\n",
    "\n",
    "colts2018 = colts2018[colts2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "colts2018 = colts2018.reset_index(drop = True)\n",
    "\n",
    "colts2019 = colts2019[colts2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "colts2019 = colts2019.reset_index(drop = True)\n",
    "\n",
    "colts2020 = colts2020[colts2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "colts2020 = colts2020.reset_index(drop = True)\n",
    "\n",
    "colts2015.to_csv('../cleanest_data/colts2015.csv', index = False)\n",
    "colts2016.to_csv('../cleanest_data/colts2016.csv', index = False)\n",
    "colts2017.to_csv('../cleanest_data/colts2017.csv', index = False)\n",
    "colts2018.to_csv('../cleanest_data/colts2018.csv', index = False)\n",
    "colts2019.to_csv('../cleanest_data/colts2019.csv', index = False)\n",
    "colts2020.to_csv('../cleanest_data/colts2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cowboys2015 = pd.read_csv('../clean_data/cowboys2015.csv')\n",
    "cowboys2016 = pd.read_csv('../clean_data/cowboys2016.csv')\n",
    "cowboys2017 = pd.read_csv('../clean_data/cowboys2017.csv')\n",
    "cowboys2018 = pd.read_csv('../clean_data/cowboys2018.csv')\n",
    "cowboys2019 = pd.read_csv('../clean_data/cowboys2019.csv')\n",
    "cowboys2020 = pd.read_csv('../clean_data/cowboys2020.csv')\n",
    "\n",
    "cowboys2015 = cowboys2015[cowboys2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "cowboys2015 = cowboys2015.reset_index(drop = True)\n",
    "\n",
    "cowboys2016 = cowboys2016[cowboys2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "cowboys2016 = cowboys2016.reset_index(drop = True)\n",
    "\n",
    "cowboys2017 = cowboys2017[cowboys2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "cowboys2017 = cowboys2017.reset_index(drop = True)\n",
    "\n",
    "cowboys2018 = cowboys2018[cowboys2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "cowboys2018 = cowboys2018.reset_index(drop = True)\n",
    "\n",
    "cowboys2019 = cowboys2019[cowboys2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "cowboys2019 = cowboys2019.reset_index(drop = True)\n",
    "\n",
    "cowboys2020 = cowboys2020[cowboys2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "cowboys2020 = cowboys2020.reset_index(drop = True)\n",
    "\n",
    "cowboys2015.to_csv('../cleanest_data/cowboys2015.csv', index = False)\n",
    "cowboys2016.to_csv('../cleanest_data/cowboys2016.csv', index = False)\n",
    "cowboys2017.to_csv('../cleanest_data/cowboys2017.csv', index = False)\n",
    "cowboys2018.to_csv('../cleanest_data/cowboys2018.csv', index = False)\n",
    "cowboys2019.to_csv('../cleanest_data/cowboys2019.csv', index = False)\n",
    "cowboys2020.to_csv('../cleanest_data/cowboys2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolphins2015 = pd.read_csv('../clean_data/dolphins2015.csv')\n",
    "dolphins2016 = pd.read_csv('../clean_data/dolphins2016.csv')\n",
    "dolphins2017 = pd.read_csv('../clean_data/dolphins2017.csv')\n",
    "dolphins2018 = pd.read_csv('../clean_data/dolphins2018.csv')\n",
    "dolphins2019 = pd.read_csv('../clean_data/dolphins2019.csv')\n",
    "dolphins2020 = pd.read_csv('../clean_data/dolphins2020.csv')\n",
    "\n",
    "dolphins2015 = dolphins2015[dolphins2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "dolphins2015 = dolphins2015.reset_index(drop = True)\n",
    "\n",
    "dolphins2016 = dolphins2016[dolphins2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "dolphins2016 = dolphins2016.reset_index(drop = True)\n",
    "\n",
    "dolphins2017 = dolphins2017[dolphins2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "dolphins2017 = dolphins2017.reset_index(drop = True)\n",
    "\n",
    "dolphins2018 = dolphins2018[dolphins2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "dolphins2018 = dolphins2018.reset_index(drop = True)\n",
    "\n",
    "dolphins2019 = dolphins2019[dolphins2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "dolphins2019 = dolphins2019.reset_index(drop = True)\n",
    "\n",
    "dolphins2020 = dolphins2020[dolphins2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "dolphins2020 = dolphins2020.reset_index(drop = True)\n",
    "\n",
    "dolphins2015.to_csv('../cleanest_data/dolphins2015.csv', index = False)\n",
    "dolphins2016.to_csv('../cleanest_data/dolphins2016.csv', index = False)\n",
    "dolphins2017.to_csv('../cleanest_data/dolphins2017.csv', index = False)\n",
    "dolphins2018.to_csv('../cleanest_data/dolphins2018.csv', index = False)\n",
    "dolphins2019.to_csv('../cleanest_data/dolphins2019.csv', index = False)\n",
    "dolphins2020.to_csv('../cleanest_data/dolphins2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eagles2015 = pd.read_csv('../clean_data/eagles2015.csv')\n",
    "eagles2016 = pd.read_csv('../clean_data/eagles2016.csv')\n",
    "eagles2017 = pd.read_csv('../clean_data/eagles2017.csv')\n",
    "eagles2018 = pd.read_csv('../clean_data/eagles2018.csv')\n",
    "eagles2019 = pd.read_csv('../clean_data/eagles2019.csv')\n",
    "eagles2020 = pd.read_csv('../clean_data/eagles2020.csv')\n",
    "\n",
    "eagles2015 = eagles2015[eagles2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "eagles2015 = eagles2015.reset_index(drop = True)\n",
    "\n",
    "eagles2016 = eagles2016[eagles2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "eagles2016 = eagles2016.reset_index(drop = True)\n",
    "\n",
    "eagles2017 = eagles2017[eagles2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "eagles2017 = eagles2017.reset_index(drop = True)\n",
    "\n",
    "eagles2018 = eagles2018[eagles2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "eagles2018 = eagles2018.reset_index(drop = True)\n",
    "\n",
    "eagles2019 = eagles2019[eagles2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "eagles2019 = eagles2019.reset_index(drop = True)\n",
    "\n",
    "eagles2020 = eagles2020[eagles2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "eagles2020 = eagles2020.reset_index(drop = True)\n",
    "\n",
    "eagles2015.to_csv('../cleanest_data/eagles2015.csv', index = False)\n",
    "eagles2016.to_csv('../cleanest_data/eagles2016.csv', index = False)\n",
    "eagles2017.to_csv('../cleanest_data/eagles2017.csv', index = False)\n",
    "eagles2018.to_csv('../cleanest_data/eagles2018.csv', index = False)\n",
    "eagles2019.to_csv('../cleanest_data/eagles2019.csv', index = False)\n",
    "eagles2020.to_csv('../cleanest_data/eagles2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "falcons2015 = pd.read_csv('../clean_data/falcons2015.csv')\n",
    "falcons2016 = pd.read_csv('../clean_data/falcons2016.csv')\n",
    "falcons2017 = pd.read_csv('../clean_data/falcons2017.csv')\n",
    "falcons2018 = pd.read_csv('../clean_data/falcons2018.csv')\n",
    "falcons2019 = pd.read_csv('../clean_data/falcons2019.csv')\n",
    "falcons2020 = pd.read_csv('../clean_data/falcons2020.csv')\n",
    "\n",
    "falcons2015 = falcons2015[falcons2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "falcons2015 = falcons2015.reset_index(drop = True)\n",
    "\n",
    "falcons2016 = falcons2016[falcons2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "falcons2016 = falcons2016.reset_index(drop = True)\n",
    "\n",
    "falcons2017 = falcons2017[falcons2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "falcons2017 = falcons2017.reset_index(drop = True)\n",
    "\n",
    "falcons2018 = falcons2018[falcons2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "falcons2018 = falcons2018.reset_index(drop = True)\n",
    "\n",
    "falcons2019 = falcons2019[falcons2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "falcons2019 = falcons2019.reset_index(drop = True)\n",
    "\n",
    "falcons2020 = falcons2020[falcons2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "falcons2020 = falcons2020.reset_index(drop = True)\n",
    "\n",
    "falcons2015.to_csv('../cleanest_data/falcons2015.csv', index = False)\n",
    "falcons2016.to_csv('../cleanest_data/falcons2016.csv', index = False)\n",
    "falcons2017.to_csv('../cleanest_data/falcons2017.csv', index = False)\n",
    "falcons2018.to_csv('../cleanest_data/falcons2018.csv', index = False)\n",
    "falcons2019.to_csv('../cleanest_data/falcons2019.csv', index = False)\n",
    "falcons2020.to_csv('../cleanest_data/falcons2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourtyniners2015 = pd.read_csv('../clean_data/fourtyniners2015.csv')\n",
    "fourtyniners2016 = pd.read_csv('../clean_data/fourtyniners2016.csv')\n",
    "fourtyniners2017 = pd.read_csv('../clean_data/fourtyniners2017.csv')\n",
    "fourtyniners2018 = pd.read_csv('../clean_data/fourtyniners2018.csv')\n",
    "fourtyniners2019 = pd.read_csv('../clean_data/fourtyniners2019.csv')\n",
    "fourtyniners2020 = pd.read_csv('../clean_data/fourtyniners2020.csv')\n",
    "\n",
    "fourtyniners2015 = fourtyniners2015[fourtyniners2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "fourtyniners2015 = fourtyniners2015.reset_index(drop = True)\n",
    "\n",
    "fourtyniners2016 = fourtyniners2016[fourtyniners2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "fourtyniners2016 = fourtyniners2016.reset_index(drop = True)\n",
    "\n",
    "fourtyniners2017 = fourtyniners2017[fourtyniners2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "fourtyniners2017 = fourtyniners2017.reset_index(drop = True)\n",
    "\n",
    "fourtyniners2018 = fourtyniners2018[fourtyniners2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "fourtyniners2018 = fourtyniners2018.reset_index(drop = True)\n",
    "\n",
    "fourtyniners2019 = fourtyniners2019[fourtyniners2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "fourtyniners2019 = fourtyniners2019.reset_index(drop = True)\n",
    "\n",
    "fourtyniners2020 = fourtyniners2020[fourtyniners2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "fourtyniners2020 = fourtyniners2020.reset_index(drop = True)\n",
    "\n",
    "fourtyniners2015.to_csv('../cleanest_data/fourtyniners2015.csv', index = False)\n",
    "fourtyniners2016.to_csv('../cleanest_data/fourtyniners2016.csv', index = False)\n",
    "fourtyniners2017.to_csv('../cleanest_data/fourtyniners2017.csv', index = False)\n",
    "fourtyniners2018.to_csv('../cleanest_data/fourtyniners2018.csv', index = False)\n",
    "fourtyniners2019.to_csv('../cleanest_data/fourtyniners2019.csv', index = False)\n",
    "fourtyniners2020.to_csv('../cleanest_data/fourtyniners2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "giants2015 = pd.read_csv('../clean_data/giants2015.csv')\n",
    "giants2016 = pd.read_csv('../clean_data/giants2016.csv')\n",
    "giants2017 = pd.read_csv('../clean_data/giants2017.csv')\n",
    "giants2018 = pd.read_csv('../clean_data/giants2018.csv')\n",
    "giants2019 = pd.read_csv('../clean_data/giants2019.csv')\n",
    "giants2020 = pd.read_csv('../clean_data/giants2020.csv')\n",
    "\n",
    "giants2015 = giants2015[giants2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "giants2015 = giants2015.reset_index(drop = True)\n",
    "\n",
    "giants2016 = giants2016[giants2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "giants2016 = giants2016.reset_index(drop = True)\n",
    "\n",
    "giants2017 = giants2017[giants2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "giants2017 = giants2017.reset_index(drop = True)\n",
    "\n",
    "giants2018 = giants2018[giants2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "giants2018 = giants2018.reset_index(drop = True)\n",
    "\n",
    "giants2019 = giants2019[giants2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "giants2019 = giants2019.reset_index(drop = True)\n",
    "\n",
    "giants2020 = giants2020[giants2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "giants2020 = giants2020.reset_index(drop = True)\n",
    "\n",
    "giants2015.to_csv('../cleanest_data/giants2015.csv', index = False)\n",
    "giants2016.to_csv('../cleanest_data/giants2016.csv', index = False)\n",
    "giants2017.to_csv('../cleanest_data/giants2017.csv', index = False)\n",
    "giants2018.to_csv('../cleanest_data/giants2018.csv', index = False)\n",
    "giants2019.to_csv('../cleanest_data/giants2019.csv', index = False)\n",
    "giants2020.to_csv('../cleanest_data/giants2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaguars2015 = pd.read_csv('../clean_data/jaguars2015.csv')\n",
    "jaguars2016 = pd.read_csv('../clean_data/jaguars2016.csv')\n",
    "jaguars2017 = pd.read_csv('../clean_data/jaguars2017.csv')\n",
    "jaguars2018 = pd.read_csv('../clean_data/jaguars2018.csv')\n",
    "jaguars2019 = pd.read_csv('../clean_data/jaguars2019.csv')\n",
    "jaguars2020 = pd.read_csv('../clean_data/jaguars2020.csv')\n",
    "\n",
    "jaguars2015 = jaguars2015[jaguars2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "jaguars2015 = jaguars2015.reset_index(drop = True)\n",
    "\n",
    "jaguars2016 = jaguars2016[jaguars2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "jaguars2016 = jaguars2016.reset_index(drop = True)\n",
    "\n",
    "jaguars2017 = jaguars2017[jaguars2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "jaguars2017 = jaguars2017.reset_index(drop = True)\n",
    "\n",
    "jaguars2018 = jaguars2018[jaguars2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "jaguars2018 = jaguars2018.reset_index(drop = True)\n",
    "\n",
    "jaguars2019 = jaguars2019[jaguars2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "jaguars2019 = jaguars2019.reset_index(drop = True)\n",
    "\n",
    "jaguars2020 = jaguars2020[jaguars2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "jaguars2020 = jaguars2020.reset_index(drop = True)\n",
    "\n",
    "jaguars2015.to_csv('../cleanest_data/jaguars2015.csv', index = False)\n",
    "jaguars2016.to_csv('../cleanest_data/jaguars2016.csv', index = False)\n",
    "jaguars2017.to_csv('../cleanest_data/jaguars2017.csv', index = False)\n",
    "jaguars2018.to_csv('../cleanest_data/jaguars2018.csv', index = False)\n",
    "jaguars2019.to_csv('../cleanest_data/jaguars2019.csv', index = False)\n",
    "jaguars2020.to_csv('../cleanest_data/jaguars2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "jets2015 = pd.read_csv('../clean_data/jets2015.csv')\n",
    "jets2016 = pd.read_csv('../clean_data/jets2016.csv')\n",
    "jets2017 = pd.read_csv('../clean_data/jets2017.csv')\n",
    "jets2018 = pd.read_csv('../clean_data/jets2018.csv')\n",
    "jets2019 = pd.read_csv('../clean_data/jets2019.csv')\n",
    "jets2020 = pd.read_csv('../clean_data/jets2020.csv')\n",
    "\n",
    "jets2015 = jets2015[jets2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "jets2015 = jets2015.reset_index(drop = True)\n",
    "\n",
    "jets2016 = jets2016[jets2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "jets2016 = jets2016.reset_index(drop = True)\n",
    "\n",
    "jets2017 = jets2017[jets2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "jets2017 = jets2017.reset_index(drop = True)\n",
    "\n",
    "jets2018 = jets2018[jets2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "jets2018 = jets2018.reset_index(drop = True)\n",
    "\n",
    "jets2019 = jets2019[jets2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "jets2019 = jets2019.reset_index(drop = True)\n",
    "\n",
    "jets2020 = jets2020[jets2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "jets2020 = jets2020.reset_index(drop = True)\n",
    "\n",
    "jets2015.to_csv('../cleanest_data/jets2015.csv', index = False)\n",
    "jets2016.to_csv('../cleanest_data/jets2016.csv', index = False)\n",
    "jets2017.to_csv('../cleanest_data/jets2017.csv', index = False)\n",
    "jets2018.to_csv('../cleanest_data/jets2018.csv', index = False)\n",
    "jets2019.to_csv('../cleanest_data/jets2019.csv', index = False)\n",
    "jets2020.to_csv('../cleanest_data/jets2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lions2015 = pd.read_csv('../clean_data/lions2015.csv')\n",
    "lions2016 = pd.read_csv('../clean_data/lions2016.csv')\n",
    "lions2017 = pd.read_csv('../clean_data/lions2017.csv')\n",
    "lions2018 = pd.read_csv('../clean_data/lions2018.csv')\n",
    "lions2019 = pd.read_csv('../clean_data/lions2019.csv')\n",
    "lions2020 = pd.read_csv('../clean_data/lions2020.csv')\n",
    "\n",
    "lions2015 = lions2015[lions2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "lions2015 = lions2015.reset_index(drop = True)\n",
    "\n",
    "lions2016 = lions2016[lions2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "lions2016 = lions2016.reset_index(drop = True)\n",
    "\n",
    "lions2017 = lions2017[lions2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "lions2017 = lions2017.reset_index(drop = True)\n",
    "\n",
    "lions2018 = lions2018[lions2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "lions2018 = lions2018.reset_index(drop = True)\n",
    "\n",
    "lions2019 = lions2019[lions2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "lions2019 = lions2019.reset_index(drop = True)\n",
    "\n",
    "lions2020 = lions2020[lions2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "lions2020 = lions2020.reset_index(drop = True)\n",
    "\n",
    "lions2015.to_csv('../cleanest_data/lions2015.csv', index = False)\n",
    "lions2016.to_csv('../cleanest_data/lions2016.csv', index = False)\n",
    "lions2017.to_csv('../cleanest_data/lions2017.csv', index = False)\n",
    "lions2018.to_csv('../cleanest_data/lions2018.csv', index = False)\n",
    "lions2019.to_csv('../cleanest_data/lions2019.csv', index = False)\n",
    "lions2020.to_csv('../cleanest_data/lions2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "packers2015 = pd.read_csv('../clean_data/packers2015.csv')\n",
    "packers2016 = pd.read_csv('../clean_data/packers2016.csv')\n",
    "packers2017 = pd.read_csv('../clean_data/packers2017.csv')\n",
    "packers2018 = pd.read_csv('../clean_data/packers2018.csv')\n",
    "packers2019 = pd.read_csv('../clean_data/packers2019.csv')\n",
    "packers2020 = pd.read_csv('../clean_data/packers2020.csv')\n",
    "\n",
    "packers2015 = packers2015[packers2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "packers2015 = packers2015.reset_index(drop = True)\n",
    "\n",
    "packers2016 = packers2016[packers2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "packers2016 = packers2016.reset_index(drop = True)\n",
    "\n",
    "packers2017 = packers2017[packers2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "packers2017 = packers2017.reset_index(drop = True)\n",
    "\n",
    "packers2018 = packers2018[packers2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "packers2018 = packers2018.reset_index(drop = True)\n",
    "\n",
    "packers2019 = packers2019[packers2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "packers2019 = packers2019.reset_index(drop = True)\n",
    "\n",
    "packers2020 = packers2020[packers2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "packers2020 = packers2020.reset_index(drop = True)\n",
    "\n",
    "packers2015.to_csv('../cleanest_data/packers2015.csv', index = False)\n",
    "packers2016.to_csv('../cleanest_data/packers2016.csv', index = False)\n",
    "packers2017.to_csv('../cleanest_data/packers2017.csv', index = False)\n",
    "packers2018.to_csv('../cleanest_data/packers2018.csv', index = False)\n",
    "packers2019.to_csv('../cleanest_data/packers2019.csv', index = False)\n",
    "packers2020.to_csv('../cleanest_data/packers2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "panthers2015 = pd.read_csv('../clean_data/panthers2015.csv')\n",
    "panthers2016 = pd.read_csv('../clean_data/panthers2016.csv')\n",
    "panthers2017 = pd.read_csv('../clean_data/panthers2017.csv')\n",
    "panthers2018 = pd.read_csv('../clean_data/panthers2018.csv')\n",
    "panthers2019 = pd.read_csv('../clean_data/panthers2019.csv')\n",
    "panthers2020 = pd.read_csv('../clean_data/panthers2020.csv')\n",
    "\n",
    "panthers2015 = panthers2015[panthers2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "panthers2015 = panthers2015.reset_index(drop = True)\n",
    "\n",
    "panthers2016 = panthers2016[panthers2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "panthers2016 = panthers2016.reset_index(drop = True)\n",
    "\n",
    "panthers2017 = panthers2017[panthers2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "panthers2017 = panthers2017.reset_index(drop = True)\n",
    "\n",
    "panthers2018 = panthers2018[panthers2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "panthers2018 = panthers2018.reset_index(drop = True)\n",
    "\n",
    "panthers2019 = panthers2019[panthers2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "panthers2019 = panthers2019.reset_index(drop = True)\n",
    "\n",
    "panthers2020 = panthers2020[panthers2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "panthers2020 = panthers2020.reset_index(drop = True)\n",
    "\n",
    "panthers2015.to_csv('../cleanest_data/panthers2015.csv', index = False)\n",
    "panthers2016.to_csv('../cleanest_data/panthers2016.csv', index = False)\n",
    "panthers2017.to_csv('../cleanest_data/panthers2017.csv', index = False)\n",
    "panthers2018.to_csv('../cleanest_data/panthers2018.csv', index = False)\n",
    "panthers2019.to_csv('../cleanest_data/panthers2019.csv', index = False)\n",
    "panthers2020.to_csv('../cleanest_data/panthers2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "patriots2015 = pd.read_csv('../clean_data/patriots2015.csv')\n",
    "patriots2016 = pd.read_csv('../clean_data/patriots2016.csv')\n",
    "patriots2017 = pd.read_csv('../clean_data/patriots2017.csv')\n",
    "patriots2018 = pd.read_csv('../clean_data/patriots2018.csv')\n",
    "patriots2019 = pd.read_csv('../clean_data/patriots2019.csv')\n",
    "patriots2020 = pd.read_csv('../clean_data/patriots2020.csv')\n",
    "\n",
    "patriots2015 = patriots2015[patriots2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "patriots2015 = patriots2015.reset_index(drop = True)\n",
    "\n",
    "patriots2016 = patriots2016[patriots2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "patriots2016 = patriots2016.reset_index(drop = True)\n",
    "\n",
    "patriots2017 = patriots2017[patriots2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "patriots2017 = patriots2017.reset_index(drop = True)\n",
    "\n",
    "patriots2018 = patriots2018[patriots2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "patriots2018 = patriots2018.reset_index(drop = True)\n",
    "\n",
    "patriots2019 = patriots2019[patriots2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "patriots2019 = patriots2019.reset_index(drop = True)\n",
    "\n",
    "patriots2020 = patriots2020[patriots2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "patriots2020 = patriots2020.reset_index(drop = True)\n",
    "\n",
    "patriots2015.to_csv('../cleanest_data/patriots2015.csv', index = False)\n",
    "patriots2016.to_csv('../cleanest_data/patriots2016.csv', index = False)\n",
    "patriots2017.to_csv('../cleanest_data/patriots2017.csv', index = False)\n",
    "patriots2018.to_csv('../cleanest_data/patriots2018.csv', index = False)\n",
    "patriots2019.to_csv('../cleanest_data/patriots2019.csv', index = False)\n",
    "patriots2020.to_csv('../cleanest_data/patriots2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "raiders2015 = pd.read_csv('../clean_data/raiders2015.csv')\n",
    "raiders2016 = pd.read_csv('../clean_data/raiders2016.csv')\n",
    "raiders2017 = pd.read_csv('../clean_data/raiders2017.csv')\n",
    "raiders2018 = pd.read_csv('../clean_data/raiders2018.csv')\n",
    "raiders2019 = pd.read_csv('../clean_data/raiders2019.csv')\n",
    "raiders2020 = pd.read_csv('../clean_data/raiders2020.csv')\n",
    "\n",
    "raiders2015 = raiders2015[raiders2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "raiders2015 = raiders2015.reset_index(drop = True)\n",
    "\n",
    "raiders2016 = raiders2016[raiders2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "raiders2016 = raiders2016.reset_index(drop = True)\n",
    "\n",
    "raiders2017 = raiders2017[raiders2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "raiders2017 = raiders2017.reset_index(drop = True)\n",
    "\n",
    "raiders2018 = raiders2018[raiders2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "raiders2018 = raiders2018.reset_index(drop = True)\n",
    "\n",
    "raiders2019 = raiders2019[raiders2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "raiders2019 = raiders2019.reset_index(drop = True)\n",
    "\n",
    "raiders2020 = raiders2020[raiders2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "raiders2020 = raiders2020.reset_index(drop = True)\n",
    "\n",
    "raiders2015.to_csv('../cleanest_data/raiders2015.csv', index = False)\n",
    "raiders2016.to_csv('../cleanest_data/raiders2016.csv', index = False)\n",
    "raiders2017.to_csv('../cleanest_data/raiders2017.csv', index = False)\n",
    "raiders2018.to_csv('../cleanest_data/raiders2018.csv', index = False)\n",
    "raiders2019.to_csv('../cleanest_data/raiders2019.csv', index = False)\n",
    "raiders2020.to_csv('../cleanest_data/raiders2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rams2015 = pd.read_csv('../clean_data/rams2015.csv')\n",
    "rams2016 = pd.read_csv('../clean_data/rams2016.csv')\n",
    "rams2017 = pd.read_csv('../clean_data/rams2017.csv')\n",
    "rams2018 = pd.read_csv('../clean_data/rams2018.csv')\n",
    "rams2019 = pd.read_csv('../clean_data/rams2019.csv')\n",
    "rams2020 = pd.read_csv('../clean_data/rams2020.csv')\n",
    "\n",
    "rams2015 = rams2015[rams2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "rams2015 = rams2015.reset_index(drop = True)\n",
    "\n",
    "rams2016 = rams2016[rams2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "rams2016 = rams2016.reset_index(drop = True)\n",
    "\n",
    "rams2017 = rams2017[rams2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "rams2017 = rams2017.reset_index(drop = True)\n",
    "\n",
    "rams2018 = rams2018[rams2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "rams2018 = rams2018.reset_index(drop = True)\n",
    "\n",
    "rams2019 = rams2019[rams2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "rams2019 = rams2019.reset_index(drop = True)\n",
    "\n",
    "rams2020 = rams2020[rams2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "rams2020 = rams2020.reset_index(drop = True)\n",
    "\n",
    "rams2015.to_csv('../cleanest_data/rams2015.csv', index = False)\n",
    "rams2016.to_csv('../cleanest_data/rams2016.csv', index = False)\n",
    "rams2017.to_csv('../cleanest_data/rams2017.csv', index = False)\n",
    "rams2018.to_csv('../cleanest_data/rams2018.csv', index = False)\n",
    "rams2019.to_csv('../cleanest_data/rams2019.csv', index = False)\n",
    "rams2020.to_csv('../cleanest_data/rams2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravens2015 = pd.read_csv('../clean_data/ravens2015.csv')\n",
    "ravens2016 = pd.read_csv('../clean_data/ravens2016.csv')\n",
    "ravens2017 = pd.read_csv('../clean_data/ravens2017.csv')\n",
    "ravens2018 = pd.read_csv('../clean_data/ravens2018.csv')\n",
    "ravens2019 = pd.read_csv('../clean_data/ravens2019.csv')\n",
    "ravens2020 = pd.read_csv('../clean_data/ravens2020.csv')\n",
    "\n",
    "ravens2015 = ravens2015[ravens2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "ravens2015 = ravens2015.reset_index(drop = True)\n",
    "\n",
    "ravens2016 = ravens2016[ravens2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "ravens2016 = ravens2016.reset_index(drop = True)\n",
    "\n",
    "ravens2017 = ravens2017[ravens2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "ravens2017 = ravens2017.reset_index(drop = True)\n",
    "\n",
    "ravens2018 = ravens2018[ravens2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "ravens2018 = ravens2018.reset_index(drop = True)\n",
    "\n",
    "ravens2019 = ravens2019[ravens2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "ravens2019 = ravens2019.reset_index(drop = True)\n",
    "\n",
    "ravens2020 = ravens2020[ravens2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "ravens2020 = ravens2020.reset_index(drop = True)\n",
    "\n",
    "ravens2015.to_csv('../cleanest_data/ravens2015.csv', index = False)\n",
    "ravens2016.to_csv('../cleanest_data/ravens2016.csv', index = False)\n",
    "ravens2017.to_csv('../cleanest_data/ravens2017.csv', index = False)\n",
    "ravens2018.to_csv('../cleanest_data/ravens2018.csv', index = False)\n",
    "ravens2019.to_csv('../cleanest_data/ravens2019.csv', index = False)\n",
    "ravens2020.to_csv('../cleanest_data/ravens2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "redskins2015 = pd.read_csv('../clean_data/redskins2015.csv')\n",
    "redskins2016 = pd.read_csv('../clean_data/redskins2016.csv')\n",
    "redskins2017 = pd.read_csv('../clean_data/redskins2017.csv')\n",
    "redskins2018 = pd.read_csv('../clean_data/redskins2018.csv')\n",
    "redskins2019 = pd.read_csv('../clean_data/redskins2019.csv')\n",
    "redskins2020 = pd.read_csv('../clean_data/redskins2020.csv')\n",
    "\n",
    "redskins2015 = redskins2015[redskins2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "redskins2015 = redskins2015.reset_index(drop = True)\n",
    "\n",
    "redskins2016 = redskins2016[redskins2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "redskins2016 = redskins2016.reset_index(drop = True)\n",
    "\n",
    "redskins2017 = redskins2017[redskins2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "redskins2017 = redskins2017.reset_index(drop = True)\n",
    "\n",
    "redskins2018 = redskins2018[redskins2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "redskins2018 = redskins2018.reset_index(drop = True)\n",
    "\n",
    "redskins2019 = redskins2019[redskins2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "redskins2019 = redskins2019.reset_index(drop = True)\n",
    "\n",
    "redskins2020 = redskins2020[redskins2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "redskins2020 = redskins2020.reset_index(drop = True)\n",
    "\n",
    "redskins2015.to_csv('../cleanest_data/redskins2015.csv', index = False)\n",
    "redskins2016.to_csv('../cleanest_data/redskins2016.csv', index = False)\n",
    "redskins2017.to_csv('../cleanest_data/redskins2017.csv', index = False)\n",
    "redskins2018.to_csv('../cleanest_data/redskins2018.csv', index = False)\n",
    "redskins2019.to_csv('../cleanest_data/redskins2019.csv', index = False)\n",
    "redskins2020.to_csv('../cleanest_data/redskins2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "saints2015 = pd.read_csv('../clean_data/saints2015.csv')\n",
    "saints2016 = pd.read_csv('../clean_data/saints2016.csv')\n",
    "saints2017 = pd.read_csv('../clean_data/saints2017.csv')\n",
    "saints2018 = pd.read_csv('../clean_data/saints2018.csv')\n",
    "saints2019 = pd.read_csv('../clean_data/saints2019.csv')\n",
    "saints2020 = pd.read_csv('../clean_data/saints2020.csv')\n",
    "\n",
    "saints2015 = saints2015[saints2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "saints2015 = saints2015.reset_index(drop = True)\n",
    "\n",
    "saints2016 = saints2016[saints2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "saints2016 = saints2016.reset_index(drop = True)\n",
    "\n",
    "saints2017 = saints2017[saints2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "saints2017 = saints2017.reset_index(drop = True)\n",
    "\n",
    "saints2018 = saints2018[saints2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "saints2018 = saints2018.reset_index(drop = True)\n",
    "\n",
    "saints2019 = saints2019[saints2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "saints2019 = saints2019.reset_index(drop = True)\n",
    "\n",
    "saints2020 = saints2020[saints2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "saints2020 = saints2020.reset_index(drop = True)\n",
    "\n",
    "saints2015.to_csv('../cleanest_data/saints2015.csv', index = False)\n",
    "saints2016.to_csv('../cleanest_data/saints2016.csv', index = False)\n",
    "saints2017.to_csv('../cleanest_data/saints2017.csv', index = False)\n",
    "saints2018.to_csv('../cleanest_data/saints2018.csv', index = False)\n",
    "saints2019.to_csv('../cleanest_data/saints2019.csv', index = False)\n",
    "saints2020.to_csv('../cleanest_data/saints2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "seahawks2015 = pd.read_csv('../clean_data/seahawks2015.csv')\n",
    "seahawks2016 = pd.read_csv('../clean_data/seahawks2016.csv')\n",
    "seahawks2017 = pd.read_csv('../clean_data/seahawks2017.csv')\n",
    "seahawks2018 = pd.read_csv('../clean_data/seahawks2018.csv')\n",
    "seahawks2019 = pd.read_csv('../clean_data/seahawks2019.csv')\n",
    "seahawks2020 = pd.read_csv('../clean_data/seahawks2020.csv')\n",
    "\n",
    "seahawks2015 = seahawks2015[seahawks2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "seahawks2015 = seahawks2015.reset_index(drop = True)\n",
    "\n",
    "seahawks2016 = seahawks2016[seahawks2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "seahawks2016 = seahawks2016.reset_index(drop = True)\n",
    "\n",
    "seahawks2017 = seahawks2017[seahawks2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "seahawks2017 = seahawks2017.reset_index(drop = True)\n",
    "\n",
    "seahawks2018 = seahawks2018[seahawks2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "seahawks2018 = seahawks2018.reset_index(drop = True)\n",
    "\n",
    "seahawks2019 = seahawks2019[seahawks2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "seahawks2019 = seahawks2019.reset_index(drop = True)\n",
    "\n",
    "seahawks2020 = seahawks2020[seahawks2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "seahawks2020 = seahawks2020.reset_index(drop = True)\n",
    "\n",
    "seahawks2015.to_csv('../cleanest_data/seahawks2015.csv', index = False)\n",
    "seahawks2016.to_csv('../cleanest_data/seahawks2016.csv', index = False)\n",
    "seahawks2017.to_csv('../cleanest_data/seahawks2017.csv', index = False)\n",
    "seahawks2018.to_csv('../cleanest_data/seahawks2018.csv', index = False)\n",
    "seahawks2019.to_csv('../cleanest_data/seahawks2019.csv', index = False)\n",
    "seahawks2020.to_csv('../cleanest_data/seahawks2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "steelers2015 = pd.read_csv('../clean_data/steelers2015.csv')\n",
    "steelers2016 = pd.read_csv('../clean_data/steelers2016.csv')\n",
    "steelers2017 = pd.read_csv('../clean_data/steelers2017.csv')\n",
    "steelers2018 = pd.read_csv('../clean_data/steelers2018.csv')\n",
    "steelers2019 = pd.read_csv('../clean_data/steelers2019.csv')\n",
    "steelers2020 = pd.read_csv('../clean_data/steelers2020.csv')\n",
    "\n",
    "steelers2015 = steelers2015[steelers2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "steelers2015 = steelers2015.reset_index(drop = True)\n",
    "\n",
    "steelers2016 = steelers2016[steelers2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "steelers2016 = steelers2016.reset_index(drop = True)\n",
    "\n",
    "steelers2017 = steelers2017[steelers2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "steelers2017 = steelers2017.reset_index(drop = True)\n",
    "\n",
    "steelers2018 = steelers2018[steelers2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "steelers2018 = steelers2018.reset_index(drop = True)\n",
    "\n",
    "steelers2019 = steelers2019[steelers2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "steelers2019 = steelers2019.reset_index(drop = True)\n",
    "\n",
    "steelers2020 = steelers2020[steelers2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "steelers2020 = steelers2020.reset_index(drop = True)\n",
    "\n",
    "steelers2015.to_csv('../cleanest_data/steelers2015.csv', index = False)\n",
    "steelers2016.to_csv('../cleanest_data/steelers2016.csv', index = False)\n",
    "steelers2017.to_csv('../cleanest_data/steelers2017.csv', index = False)\n",
    "steelers2018.to_csv('../cleanest_data/steelers2018.csv', index = False)\n",
    "steelers2019.to_csv('../cleanest_data/steelers2019.csv', index = False)\n",
    "steelers2020.to_csv('../cleanest_data/steelers2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "texans2015 = pd.read_csv('../clean_data/texans2015.csv')\n",
    "texans2016 = pd.read_csv('../clean_data/texans2016.csv')\n",
    "texans2017 = pd.read_csv('../clean_data/texans2017.csv')\n",
    "texans2018 = pd.read_csv('../clean_data/texans2018.csv')\n",
    "texans2019 = pd.read_csv('../clean_data/texans2019.csv')\n",
    "texans2020 = pd.read_csv('../clean_data/texans2020.csv')\n",
    "\n",
    "texans2015 = texans2015[texans2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "texans2015 = texans2015.reset_index(drop = True)\n",
    "\n",
    "texans2016 = texans2016[texans2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "texans2016 = texans2016.reset_index(drop = True)\n",
    "\n",
    "texans2017 = texans2017[texans2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "texans2017 = texans2017.reset_index(drop = True)\n",
    "\n",
    "texans2018 = texans2018[texans2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "texans2018 = texans2018.reset_index(drop = True)\n",
    "\n",
    "texans2019 = texans2019[texans2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "texans2019 = texans2019.reset_index(drop = True)\n",
    "\n",
    "texans2020 = texans2020[texans2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "texans2020 = texans2020.reset_index(drop = True)\n",
    "\n",
    "texans2015.to_csv('../cleanest_data/texans2015.csv', index = False)\n",
    "texans2016.to_csv('../cleanest_data/texans2016.csv', index = False)\n",
    "texans2017.to_csv('../cleanest_data/texans2017.csv', index = False)\n",
    "texans2018.to_csv('../cleanest_data/texans2018.csv', index = False)\n",
    "texans2019.to_csv('../cleanest_data/texans2019.csv', index = False)\n",
    "texans2020.to_csv('../cleanest_data/texans2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "titans2015 = pd.read_csv('../clean_data/titans2015.csv')\n",
    "titans2016 = pd.read_csv('../clean_data/titans2016.csv')\n",
    "titans2017 = pd.read_csv('../clean_data/titans2017.csv')\n",
    "titans2018 = pd.read_csv('../clean_data/titans2018.csv')\n",
    "titans2019 = pd.read_csv('../clean_data/titans2019.csv')\n",
    "titans2020 = pd.read_csv('../clean_data/titans2020.csv')\n",
    "\n",
    "titans2015 = titans2015[titans2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "titans2015 = titans2015.reset_index(drop = True)\n",
    "\n",
    "titans2016 = titans2016[titans2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "titans2016 = titans2016.reset_index(drop = True)\n",
    "\n",
    "titans2017 = titans2017[titans2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "titans2017 = titans2017.reset_index(drop = True)\n",
    "\n",
    "titans2018 = titans2018[titans2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "titans2018 = titans2018.reset_index(drop = True)\n",
    "\n",
    "titans2019 = titans2019[titans2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "titans2019 = titans2019.reset_index(drop = True)\n",
    "\n",
    "titans2020 = titans2020[titans2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "titans2020 = titans2020.reset_index(drop = True)\n",
    "\n",
    "titans2015.to_csv('../cleanest_data/titans2015.csv', index = False)\n",
    "titans2016.to_csv('../cleanest_data/titans2016.csv', index = False)\n",
    "titans2017.to_csv('../cleanest_data/titans2017.csv', index = False)\n",
    "titans2018.to_csv('../cleanest_data/titans2018.csv', index = False)\n",
    "titans2019.to_csv('../cleanest_data/titans2019.csv', index = False)\n",
    "titans2020.to_csv('../cleanest_data/titans2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vikings2015 = pd.read_csv('../clean_data/vikings2015.csv')\n",
    "vikings2016 = pd.read_csv('../clean_data/vikings2016.csv')\n",
    "vikings2017 = pd.read_csv('../clean_data/vikings2017.csv')\n",
    "vikings2018 = pd.read_csv('../clean_data/vikings2018.csv')\n",
    "vikings2019 = pd.read_csv('../clean_data/vikings2019.csv')\n",
    "vikings2020 = pd.read_csv('../clean_data/vikings2020.csv')\n",
    "\n",
    "vikings2015 = vikings2015[vikings2015.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "vikings2015 = vikings2015.reset_index(drop = True)\n",
    "\n",
    "vikings2016 = vikings2016[vikings2016.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "vikings2016 = vikings2016.reset_index(drop = True)\n",
    "\n",
    "vikings2017 = vikings2017[vikings2017.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "vikings2017 = vikings2017.reset_index(drop = True)\n",
    "\n",
    "vikings2018 = vikings2018[vikings2018.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "vikings2018 = vikings2018.reset_index(drop = True)\n",
    "\n",
    "vikings2019 = vikings2019[vikings2019.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "vikings2019 = vikings2019.reset_index(drop = True)\n",
    "\n",
    "vikings2020 = vikings2020[vikings2020.apply(lambda row: row.astype(str).str.contains('PUP|O|IR|D').any(), axis=1)]\n",
    "vikings2020 = vikings2020.reset_index(drop = True)\n",
    "\n",
    "vikings2015.to_csv('../cleanest_data/vikings2015.csv', index = False)\n",
    "vikings2016.to_csv('../cleanest_data/vikings2016.csv', index = False)\n",
    "vikings2017.to_csv('../cleanest_data/vikings2017.csv', index = False)\n",
    "vikings2018.to_csv('../cleanest_data/vikings2018.csv', index = False)\n",
    "vikings2019.to_csv('../cleanest_data/vikings2019.csv', index = False)\n",
    "vikings2020.to_csv('../cleanest_data/vikings2020.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Week 1</th>\n",
       "      <th>Week 2</th>\n",
       "      <th>Week 3</th>\n",
       "      <th>Week 4</th>\n",
       "      <th>Week 5</th>\n",
       "      <th>Week 6</th>\n",
       "      <th>Week 7</th>\n",
       "      <th>Week 8</th>\n",
       "      <th>Week 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Week 12</th>\n",
       "      <th>Week 13</th>\n",
       "      <th>Week 14</th>\n",
       "      <th>Week 15</th>\n",
       "      <th>Week 16</th>\n",
       "      <th>Age</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Team</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mackensie Alexander</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blake Bell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sam Bradford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>Q</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>...</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Teddy Bridgewater</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>...</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tramaine Brock</td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dalvin Cook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>...</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>22.0</td>\n",
       "      <td>rb</td>\n",
       "      <td>465000.0</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stefon Diggs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>WR</td>\n",
       "      <td>615000.0</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nick Easton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR</td>\n",
       "      <td>25.0</td>\n",
       "      <td>LG</td>\n",
       "      <td>615000.0</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pat Elflein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>23.0</td>\n",
       "      <td>C</td>\n",
       "      <td>465000.0</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sharrif Floyd</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>...</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rashod Hill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>rt</td>\n",
       "      <td>540000.0</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Datone Jones</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>IR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kevin McDermott</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>David Morgan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>te</td>\n",
       "      <td>540000.0</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Terence Newman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>DB</td>\n",
       "      <td>2400000.0</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Riley Reiff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>LT</td>\n",
       "      <td>6200000.0</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Mike Remmers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>RT</td>\n",
       "      <td>1400000.0</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kyle Rudolph</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bishop Sankey</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>...</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>IR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Andrew Sendejo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>SS</td>\n",
       "      <td>2950000.0</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Jeremiah Sirles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Shamar Stephen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Stephen Weatherly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>Q</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Player Week 1 Week 2 Week 3 Week 4 Week 5 Week 6 Week 7  \\\n",
       "0   Mackensie Alexander    NaN    NaN    NaN    NaN    NaN    NaN      Q   \n",
       "1            Blake Bell    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "2          Sam Bradford    NaN      Q      O      O      Q     IR     IR   \n",
       "3     Teddy Bridgewater     IR     IR     IR     IR     IR     IR     IR   \n",
       "4        Tramaine Brock      Q    NaN    NaN    NaN    NaN    NaN      Q   \n",
       "5           Dalvin Cook    NaN    NaN    NaN    NaN     IR     IR     IR   \n",
       "6          Stefon Diggs    NaN    NaN    NaN    NaN    NaN      O      O   \n",
       "7           Nick Easton    NaN    NaN    NaN    NaN    NaN      O      O   \n",
       "8           Pat Elflein    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "9         Sharrif Floyd     IR     IR     IR     IR     IR     IR     IR   \n",
       "10          Rashod Hill    NaN    NaN    NaN      Q      O    NaN    NaN   \n",
       "11         Datone Jones     IR     IR     IR     IR     IR     IR     IR   \n",
       "12      Kevin McDermott    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "13         David Morgan    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "14       Terence Newman    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "15          Riley Reiff    NaN    NaN    NaN    NaN    NaN    NaN      Q   \n",
       "16         Mike Remmers    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "17         Kyle Rudolph    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "18        Bishop Sankey     IR     IR     IR     IR     IR     IR     IR   \n",
       "19       Andrew Sendejo    NaN    NaN    NaN    NaN    NaN      Q    NaN   \n",
       "20      Jeremiah Sirles    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "21       Shamar Stephen    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "22    Stephen Weatherly    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "   Week 8 Week 9  ... Week 12 Week 13 Week 14 Week 15 Week 16   Age  Pos  \\\n",
       "0       Q    NaN  ...     NaN     NaN       O       Q     NaN   NaN  NaN   \n",
       "1     NaN    NaN  ...     NaN     NaN       O      IR      IR   NaN  NaN   \n",
       "2      IR     IR  ...      IR      IR      IR      IR      IR   NaN  NaN   \n",
       "3      IR     IR  ...      IR      IR     NaN      IR      IR   NaN  NaN   \n",
       "4     NaN    NaN  ...     NaN     NaN     NaN       O       O   NaN  NaN   \n",
       "5      IR     IR  ...      IR      IR      IR      IR      IR  22.0   rb   \n",
       "6       Q    NaN  ...     NaN     NaN     NaN     NaN     NaN  24.0   WR   \n",
       "7       Q    NaN  ...     NaN     NaN     NaN     NaN      IR  25.0   LG   \n",
       "8     NaN    NaN  ...     NaN       Q     NaN     NaN       O  23.0    C   \n",
       "9      IR     IR  ...      IR      IR      IR      IR      IR   NaN  NaN   \n",
       "10    NaN    NaN  ...     NaN     NaN     NaN     NaN     NaN  25.0   rt   \n",
       "11    NaN    NaN  ...      IR     NaN     NaN      IR     NaN   NaN  NaN   \n",
       "12    NaN    NaN  ...     NaN     NaN     NaN     NaN       O   NaN  NaN   \n",
       "13    NaN    NaN  ...     NaN       O     NaN     NaN     NaN  24.0   te   \n",
       "14    NaN    NaN  ...     NaN     NaN     NaN     NaN     NaN  39.0   DB   \n",
       "15      Q    NaN  ...     NaN     NaN       D       Q     NaN  29.0   LT   \n",
       "16    NaN      O  ...       O       O     NaN     NaN     NaN  28.0   RT   \n",
       "17    NaN    NaN  ...     NaN     NaN       D     NaN     NaN   NaN  NaN   \n",
       "18     IR     IR  ...      IR      IR      IR      IR      IR   NaN  NaN   \n",
       "19    NaN    NaN  ...     NaN     NaN     NaN       Q     NaN  30.0   SS   \n",
       "20      O      O  ...     NaN     NaN     NaN     NaN     NaN   NaN  NaN   \n",
       "21    NaN    NaN  ...     NaN     NaN     NaN     NaN       O   NaN  NaN   \n",
       "22      O      Q  ...     NaN     NaN     NaN     NaN     NaN   NaN  NaN   \n",
       "\n",
       "       Salary     Team  Year  \n",
       "0         NaN  Vikings  2017  \n",
       "1         NaN  Vikings  2017  \n",
       "2         NaN  Vikings  2017  \n",
       "3         NaN  Vikings  2017  \n",
       "4         NaN  Vikings  2017  \n",
       "5    465000.0  Vikings  2017  \n",
       "6    615000.0  Vikings  2017  \n",
       "7    615000.0  Vikings  2017  \n",
       "8    465000.0  Vikings  2017  \n",
       "9         NaN  Vikings  2017  \n",
       "10   540000.0  Vikings  2017  \n",
       "11        NaN  Vikings  2017  \n",
       "12        NaN  Vikings  2017  \n",
       "13   540000.0  Vikings  2017  \n",
       "14  2400000.0  Vikings  2017  \n",
       "15  6200000.0  Vikings  2017  \n",
       "16  1400000.0  Vikings  2017  \n",
       "17        NaN  Vikings  2017  \n",
       "18        NaN  Vikings  2017  \n",
       "19  2950000.0  Vikings  2017  \n",
       "20        NaN  Vikings  2017  \n",
       "21        NaN  Vikings  2017  \n",
       "22        NaN  Vikings  2017  \n",
       "\n",
       "[23 rows x 22 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vikings2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
